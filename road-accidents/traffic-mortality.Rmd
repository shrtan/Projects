---
title: "Traffic Mortality"
author: "Shreya Rao"
output:
  pdf_document: default
  html_document: default
---


While the rate of fatal road accidents has been decreasing steadily since the 80's, the past ten years have seen a stagnation in this reduction. Coupled with the increase in number of miles driven in the nation, the total number of traffic related-fatalities has now reached a ten year high and is rapidly increasing.

[This particular dataset was compiled and released as a CSV-file by FiveThirtyEight under the CC-BY4.0 license.]

```{r}
# Check the name of the current folder
current_dir <- getwd()
print(current_dir)
# List all files in this folder
file_list <- list.files()
print(file_list)
# List files inside the datasets folder
file_list_ds <- list.files("C:/Users/Shreya/Documents/Projects/")
print(file_list_ds)
# View the first 20 lines of road-accidents.csv in the datasets folder
accidents_head <- readLines("C:/Users/Shreya/Documents/Projects/road-accidents.csv", n=20) 
print(accidents_head)
```

```{r}
# Load the tidyverse library
library(tidyverse)

# Read in road-accidents.csv and set the comment argument
car_acc <- read_delim("C:/Users/Shreya/Documents/Projects/road-accidents.csv", delim = '|', comment = '#')

# Generate an overview of the data frame
str(car_acc)
# Display the last six rows of the data frame. 
tail(car_acc, 6)
```

```{r}
# Compute summary statistics of all columns in the car_acc data frame
dat_summ <- summary(car_acc)
print(dat_summ)

# Deselect the state column and create a pairwise scatterplot
library(GGally)
car_acc %>% 
    select(-state) %>%
    ggpairs()

# Using pipes, remove the state column and then compute the correlation coefficient for all column pairs 
corr_col <- car_acc %>% select(-state) %>% cor()
# Print the correlation coefficient for all column pairs
print(corr_col)
```

From the correlation table, I see that the amount of fatal accidents is most strongly correlated with alcohol consumption (first row). But in addition, I also see that some of the features are correlated with each other, for instance, speeding and alcohol consumption are positively correlated. I, therefore, want to compute the association of the target with each feature while adjusting for the effect of the remaining features. This can be done using multivariate linear regression.
```{r}
# Use lm to fit a multivariate linear regression model 
fit_reg <- lm(drvr_fatl_col_bmiles~perc_fatl_speed+perc_fatl_alcohol+perc_fatl_1st_time, data=car_acc)

# Retrieve the regression coefficients from the model fit
fit_coef <- coef(fit_reg)
print(fit_coef)
```

PCA
```{r}
# Center and standardise the three feature columns
car_acc_standised <- car_acc %>% 
    mutate(perc_fatl_speed=scale(perc_fatl_speed),
           perc_fatl_alcohol=scale(perc_fatl_alcohol),
           perc_fatl_1st_time=scale(perc_fatl_1st_time))

# Perform PCA on standardized features
pca_fit <- princomp(car_acc_standised[,c("perc_fatl_speed",
                    "perc_fatl_alcohol", "perc_fatl_1st_time")])

# Obtain the proportion of variance explained by each principle component
pr_var <- pca_fit$sdev^2
pve <- pr_var / sum(pr_var)

# Plot the proportion of variance explained, draw a point plot connected with lines
data_frame( comp_id=1:length(pve) , pve ) %>%
ggplot( aes(x=comp_id , y=pve) ) + geom_point() + geom_line() +
coord_cartesian(ylim=c(0,1)) +
labs(x="Principal Component", 
     y="Proportion of Variance Explained")

# Compute the cumulative proportion of variance and extract the variance
# explained by the first two principal components
cve <- cumsum(pve)
cve_pc2 <- cumsum(pve)
print(cve_pc2)
```


Visualize the First 2 Principle Components
```{r}
# Get the principle component scores from the PCA fit
pcomp1 <- pca_fit$scores[,1]
pcomp2 <- pca_fit$scores[,2]

# Plot the first 2 principle components in a scatterplot using ggplot
data_frame(pcomp1,pcomp2) %>%
ggplot( aes(pcomp1, pcomp2)) +
    geom_point() +
    labs(x="",y="")
```


**Find Clusters of Similar States in the Data**
```{r}
# Create a vector of 1 to 10 
k_vec <- 1:10
# Initialise vector of inertias
inertias <- rep(NA, length(k_vec))
# Initialise empty list to save K-mean fits 
mykm <- list()

for (k in k_vec) {
    # for each k, fit a K-mean model with k clusters and save it in the mykm list
    mykm[[k]] <- kmeans(car_acc_standised[,c(3,4,5)], centers=k, nstart=50)
    # for each k, get the within-cluster sum-of-squares and save
    inertias[k] <- mykm[[k]]$tot.withinss             
}

# Plot the within-cluster sum-of-squares against the number of clusters used
data_frame(k_vec,inertias) %>%
ggplot( aes(k_vec, inertias) ) +
geom_point() + geom_line() +
labs(x="Number of clusters", y="Intertias")
```


```{r}
# Obtain cluster-ids from the kmeans fit with k=3
cluster_id <- as.factor(mykm[[3]]$cluster)

# Color the points of the principle component plot according to their cluster number
data_frame(pcomp1,pcomp2) %>%
ggplot(aes(x=pcomp1,y=pcomp2)) + geom_point(aes(col=cluster_id)) +
labs(x="Principle Component 1",
    y="Principle Component 2")
```


Visualize the Feature Differences between the Clusters
```{r}
# Add cluster_id to the original data frame
car_acc$cluster <- cluster_id

# Get the data into long format and plot
car_acc %>%
    select(-drvr_fatl_col_bmiles) %>% 
    gather(key=feature, value=percent, -state, -cluster) %>%
    ggplot(aes(x=feature,y=percent, fill=cluster)) +
    geom_violin() +
    coord_flip()
```



